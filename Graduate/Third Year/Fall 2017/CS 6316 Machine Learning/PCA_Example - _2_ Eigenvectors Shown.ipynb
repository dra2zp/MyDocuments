{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function that will be used later to draw vectors on the graph (run this cell now, it won't have any effect until later.)\n",
    "def draw_vector(v0, v1, ax=None):\n",
    "    ax = ax or plt.gca()\n",
    "    arrowprops=dict(arrowstyle='->',\n",
    "                    linewidth=2,\n",
    "                    shrinkA=0, shrinkB=0)\n",
    "    ax.annotate('', v1, v0, arrowprops=arrowprops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(1)\n",
    "X = np.dot(rng.rand(2, 2), rng.randn(2, 200)).T\n",
    "# Performing PCA (documentation can be found: http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)\n",
    "pca = PCA(n_components=2, whiten=True) # Perform PCA, specifiying/choosing number of components (eigenvectors) to keep (2)\n",
    "pca.fit(X) # Once parameters above have been specified, now fit the data to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of variance explained for each components\n",
    "# This show how much varience is captured by the eigenvectors\n",
    "print('Explained variance ratio (first two components): %s' % str(pca.explained_variance_ratio_))\n",
    "print(\"\")\n",
    "print(\"In other words... we can see that:\")\n",
    "print('Varience explained by the first component: {:2.2f}%'.format(pca.explained_variance_ratio_[0]*100))\n",
    "print('Varience explained by the second component: {:2.2f}%'.format(pca.explained_variance_ratio_[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6)) \n",
    "fig.subplots_adjust(left=0.0625, right=0.95, wspace=0.1)\n",
    "\n",
    "# plot data\n",
    "print(\"Plot of what the data looks like. Can you estimate the first and second eigenvectors (principal components)?\")\n",
    "ax.scatter(X[:, 0], X[:, 1], alpha=0.2)\n",
    "ax.axis('equal');\n",
    "ax.set(xlabel='x', ylabel='y', title='Plot of Original Data')\n",
    "fig.savefig('Plot_Orig_Data.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Stop here!!!*\n",
    "\n",
    "### If this (PCA_Example - [2] Eigenvectors Shown) is the first file you ran, then please *STOP HERE* and follow the following instructions. However, if you did run the first file (PCA_Example - [1] ...) then you can skip this cell and go on to the next! Thank you.\n",
    "## -----------\n",
    "\n",
    "Do not go any further or run any other files. Before showing the final result of the principal components...\n",
    "\n",
    "Look at the plot created of the data (generated by the cell immediately above this one). Can you estimate what the first and second eigenvectors (principal compenents) will be? Where could they be placed? Discuss with a partner.\n",
    "\n",
    "You may very roughly sketch the plot on paper and draw where you feel the first and second eigenvectors would be. If you have any questions or are unsure what to do, please raise your hand and as the professor. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *You may now continue...*\n",
    "\n",
    "You may now run the last cell! Observe the output. Discuss with a partner. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 6)) # was 1, 2, ...\n",
    "fig.subplots_adjust(left=0.0625, right=0.95, wspace=0.1)\n",
    "\n",
    "# plot data ~ original data (with original axis) including the two eigenvectors (principal components)\n",
    "ax[0].scatter(X[:, 0], X[:, 1], alpha=0.2)\n",
    "for length, vector in zip(pca.explained_variance_, pca.components_):\n",
    "    v = vector * 3 * np.sqrt(length)\n",
    "    draw_vector(pca.mean_, pca.mean_ + v, ax=ax[0])  # using the draw_vector function\n",
    "ax[0].axis('equal');\n",
    "ax[0].set(xlabel='x', ylabel='y', title='Original Data with first and second eigenvectors (principal components) shown')\n",
    "\n",
    "# plot data ~ transformed data including the two eigenvectors (principal components)\n",
    "X_pca = pca.transform(X) # ** Transform the data to align to the selected two eigenvectors **\n",
    "ax[1].scatter(X_pca[:, 0], X_pca[:, 1], alpha=0.2)\n",
    "draw_vector([0, 0], [0, 3], ax=ax[1])  # using the draw_vector function\n",
    "draw_vector([0, 0], [3, 0], ax=ax[1])  # using the draw_vector function\n",
    "ax[1].axis('equal')\n",
    "ax[1].set(xlabel='component 1', ylabel='component 2',\n",
    "          title='Transformed data with principal components shown',\n",
    "          xlim=(-5, 5), ylim=(-3, 3.1))\n",
    "\n",
    "fig.savefig('PCA-rotation.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Were you successful in guessing where the eigenvectors would be?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
